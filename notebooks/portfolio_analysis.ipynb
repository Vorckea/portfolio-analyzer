{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced Portfolio Optimization & Risk Analytics\n",
                "\n",
                "This notebook demonstrates a robust workflow for constructing and analyzing investment portfolios using modern quantitative finance techniques. The workflow includes:\n",
                "\n",
                "1. **Configuration & Data Pipeline**: Parameter setup and data processing using advanced estimation methods.\n",
                "2. **Interactive Optimization**: Determining optimal portfolio weights to maximize risk-adjusted returns.\n",
                "3. **Risk & Return Simulation**: Projecting future performance and quantifying risk via Monte Carlo simulation.\n",
                "\n",
                "All core logic is modularized in the accompanying Python modules, ensuring this notebook remains focused on high-level analysis and results."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Configuration"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-07-12 16:16:27 - root - INFO - Logging configured. Console level: INFO, File level: DEBUG\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import yfinance as yf\n",
                "from IPython.display import clear_output\n",
                "from ipywidgets import FloatSlider, IntSlider, interact\n",
                "\n",
                "from portfolio_analyzer.analysis.backtester import Backtester\n",
                "from portfolio_analyzer.analysis.monte_carlo_simulator import (\n",
                "    MonteCarloSimulator,\n",
                "    SimulationStatisticsCalculator,\n",
                ")\n",
                "from portfolio_analyzer.config.config import AppConfig\n",
                "from portfolio_analyzer.core.portfolio_optimizer import PortfolioOptimizer\n",
                "from portfolio_analyzer.data import data_fetcher\n",
                "from portfolio_analyzer.data import input_preparator as ip\n",
                "from portfolio_analyzer.interactive.session import PortfolioAnalysisSession\n",
                "from portfolio_analyzer.logging_config import setup_logging\n",
                "from portfolio_analyzer.reporting.display import (\n",
                "    display_backtest_summary_html,\n",
                "    display_optimization_summary_html,\n",
                ")\n",
                "from portfolio_analyzer.reporting.plotting import (\n",
                "    calculate_correlation_matrix,\n",
                "    plot_backtest_results,\n",
                "    plot_correlation_heatmap,\n",
                "    plot_correlation_network,\n",
                "    plot_efficient_frontier,\n",
                ")\n",
                "\n",
                "setup_logging()\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
                "sns.set_context(\"notebook\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2. Define Parameters\n",
                "\n",
                "All key parameters are managed via the [`AppConfig`](../src/portfolio_analyzer/config.py) class. This centralizes control over tickers, date ranges, and model hyperparameters. User-defined views for the Black-Litterman model can also be specified here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- General Model Configuration ---\n",
                "config = AppConfig.get_instance()\n",
                "config.monte_carlo.num_simulations = 1000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Pipeline & Input Preparation\n",
                "\n",
                "The [`input_preparator`](../src/portfolio_analyzer/data/input_preparator.py) module encapsulates the end-to-end data pipeline: fetching historical prices and market capitalizations, computing log returns, and preparing the mean return vector and covariance matrix for optimization.\n",
                "\n",
                "**Note:** If enabled, the pipeline automatically performs DCF analysis for each asset to generate forward-looking views for the Black-Litterman model. Assets lacking market capitalization default to their implied equilibrium return, blending market-neutral priors with DCF-based views.\n",
                "\n",
                "Robust estimation techniques such as EWMA, Ledoit-Wolf shrinkage, and Black-Litterman blending are used to ensure stability and reliability of model inputs.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-07-12 16:16:27 - portfolio_analyzer.data.input_preparator - INFO - --- Starting Data Pipeline for 21 tickers from 2020-07-13 to 2025-07-12 ---\n",
                        "2025-07-12 16:16:27 - portfolio_analyzer.data.input_preparator - INFO - DCF Views Enabled: True\n",
                        "2025-07-12 16:16:27 - portfolio_analyzer.data.data_fetcher - INFO - Fetching historical price data for 21 tickers...\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - \n",
                        "13 Failed downloads:\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['SALME.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 6501 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['SAAB-B.ST']: Timeout('Failed to perform, curl: (28) Operation timed out after 10009 milliseconds with 20795 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['SAMPO.HE']: Timeout('Failed to perform, curl: (28) Operation timed out after 10015 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['KNEBV.HE', 'MULTI.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10011 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['0P00000B0I', '0P0001IMY8.F']: Timeout('Failed to perform, curl: (28) Operation timed out after 10007 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['SEA1.OL', 'TEL.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10002 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['KOG.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10000 milliseconds with 11695 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['SWED-A.ST']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 3901 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['EPR.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10010 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - yfinance - ERROR - ['NORCO.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10012 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:19:03 - portfolio_analyzer.data.data_fetcher - WARNING - Failed to fetch price data for: NORCO.OL, SAMPO.HE, SWED-A.ST, SALME.OL, 0P0001IMY8.F, SAAB-B.ST, 0P00000B0I, SEA1.OL, KOG.OL, TEL.OL, MULTI.OL, KNEBV.HE, EPR.OL\n",
                        "2025-07-12 16:19:03 - portfolio_analyzer.data.input_preparator - INFO - Proceeding with 8 tickers that have valid price data.\n",
                        "2025-07-12 16:19:24 - portfolio_analyzer.data.data_fetcher - INFO - Fetching historical price data for 1 tickers...\n",
                        "Ticker: NORBT.OL, Beta: 0.39, Expected Return: 0.0785\n",
                        "Ticker: SAAB-B.ST, Beta: 0.08, Expected Return: 0.0482\n",
                        "Ticker: DNB.OL, Beta: 0.42, Expected Return: 0.0816\n",
                        "Ticker: TEL.OL, Beta: 0.21, Expected Return: 0.0610\n",
                        "Ticker: ORK.OL, Beta: 0.08, Expected Return: 0.0485\n",
                        "Ticker: SAMPO.HE, Beta: 0.43, Expected Return: 0.0824\n",
                        "Ticker: STB.OL, Beta: 0.78, Expected Return: 0.1170\n",
                        "Ticker: SEA1.OL, Beta: 0.87, Expected Return: 0.1261\n",
                        "Ticker: SALME.OL, Beta: 0.57, Expected Return: 0.0960\n",
                        "Ticker: KOG.OL, Beta: 0.23, Expected Return: 0.0631\n",
                        "Ticker: KNEBV.HE, Beta: 0.68, Expected Return: 0.1071\n",
                        "Ticker: SHB-A.ST, Beta: 0.55, Expected Return: 0.0941\n",
                        "Ticker: MULTI.OL, Beta: 0.60, Expected Return: 0.0999\n",
                        "Ticker: EPR.OL, Beta: 0.45, Expected Return: 0.0849\n",
                        "Ticker: SWED-A.ST, Beta: 0.51, Expected Return: 0.0910\n",
                        "Ticker: ORNBV.HE, Beta: 0.37, Expected Return: 0.0769\n",
                        "Ticker: MAERSK-B.CO, Beta: 0.89, Expected Return: 0.1275\n",
                        "2025-07-12 16:19:53 - portfolio_analyzer.data.data_fetcher - INFO - Fetching historical price data for 21 tickers...\n",
                        "2025-07-12 16:20:47 - yfinance - ERROR - \n",
                        "1 Failed download:\n",
                        "2025-07-12 16:20:47 - yfinance - ERROR - ['NORBT.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10008 milliseconds with 10 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:20:47 - portfolio_analyzer.data.data_fetcher - WARNING - Failed to fetch price data for: NORBT.OL\n",
                        "2025-07-12 16:20:47 - portfolio_analyzer.data.data_fetcher - INFO - Fetching historical price data for 21 tickers...\n",
                        "2025-07-12 16:21:53 - yfinance - ERROR - \n",
                        "3 Failed downloads:\n",
                        "2025-07-12 16:21:53 - yfinance - ERROR - ['SHB-A.ST']: Timeout('Failed to perform, curl: (28) Operation timed out after 10006 milliseconds with 27295 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:21:53 - yfinance - ERROR - ['KOG.OL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:21:53 - yfinance - ERROR - ['SWED-A.ST']: Timeout('Failed to perform, curl: (28) Recv failure: Connection was reset. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
                        "2025-07-12 16:21:54 - portfolio_analyzer.data.data_fetcher - WARNING - Failed to fetch price data for: KOG.OL, SHB-A.ST, SWED-A.ST\n",
                        "2025-07-12 16:21:54 - portfolio_analyzer.data.data_fetcher - INFO - Fetching market cap data for 18 tickers...\n",
                        "2025-07-12 16:22:01 - portfolio_analyzer.data.data_fetcher - WARNING - Market cap not available for 0P00000B0I. Defaulting to 0.\n",
                        "2025-07-12 16:22:04 - portfolio_analyzer.data.data_fetcher - WARNING - Market cap not available for 0P00000MVB.IR. Defaulting to 0.\n",
                        "2025-07-12 16:22:34 - portfolio_analyzer.data.data_fetcher - ERROR - Failed to fetch market cap for 0P0001IMY8.F due to an error: Failed to perform, curl: (28) Operation timed out after 30010 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.. Defaulting to 0.\n"
                    ]
                },
                {
                    "ename": "KeyError",
                    "evalue": "\"['KOG.OL', 'SHB-A.ST', 'SWED-A.ST'] not in index\"",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# The prepare_model_inputs function now internally handles the creation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# of DCF-based views if enabled in the config.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data_fetcher_instance \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mDataFetcher(yf)\n\u001b[1;32m----> 5\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_fetcher_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m mean_returns \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mmean_returns\n\u001b[0;32m      7\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mcov_matrix\n",
                        "File \u001b[1;32mC:\\Projects\\portfolio-analyzer\\src\\portfolio_analyzer\\data\\input_preparator.py:137\u001b[0m, in \u001b[0;36mprepare_model_inputs\u001b[1;34m(config, data_fetcher)\u001b[0m\n\u001b[0;32m    128\u001b[0m views \u001b[38;5;241m=\u001b[39m capm_return_estimator\u001b[38;5;241m.\u001b[39mget_returns()\n\u001b[0;32m    129\u001b[0m log_returns \u001b[38;5;241m=\u001b[39m calculate_log_returns(close_df)\n\u001b[0;32m    131\u001b[0m (\n\u001b[0;32m    132\u001b[0m     mean_returns,\n\u001b[0;32m    133\u001b[0m     cov_matrix,\n\u001b[0;32m    134\u001b[0m     hist_mean_returns,\n\u001b[0;32m    135\u001b[0m     implied_equilibrium_returns,\n\u001b[0;32m    136\u001b[0m     final_tickers,\n\u001b[1;32m--> 137\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdcf_views\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m ModelInputs(\n\u001b[0;32m    145\u001b[0m     mean_returns\u001b[38;5;241m=\u001b[39mmean_returns,\n\u001b[0;32m    146\u001b[0m     cov_matrix\u001b[38;5;241m=\u001b[39mcov_matrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m     implied_equilibrium_returns\u001b[38;5;241m=\u001b[39mimplied_equilibrium_returns,\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Data Pipeline Finished ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32mC:\\Projects\\portfolio-analyzer\\src\\portfolio_analyzer\\data\\input_preparator.py:49\u001b[0m, in \u001b[0;36mbuild_model_inputs\u001b[1;34m(log_returns, config, data_fetcher, dcf_views)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Assamble the final model inputs from processed log returns and views.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m ewma \u001b[38;5;241m=\u001b[39m EWMAReturn(data_fetcher\u001b[38;5;241m=\u001b[39mdata_fetcher, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m---> 49\u001b[0m bl_model \u001b[38;5;241m=\u001b[39m \u001b[43mBlackLittermanReturn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mview_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcf_views\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m blended_returns \u001b[38;5;241m=\u001b[39m BlendedReturn(\n\u001b[0;32m     56\u001b[0m     [\n\u001b[0;32m     57\u001b[0m         (bl_model, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m config\u001b[38;5;241m.\u001b[39mblack_litterman\u001b[38;5;241m.\u001b[39mmomentum_blend_weight) \u001b[38;5;28;01mif\u001b[39;00m bl_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m         (ewma, config\u001b[38;5;241m.\u001b[39mblack_litterman\u001b[38;5;241m.\u001b[39mmomentum_blend_weight),\n\u001b[0;32m     59\u001b[0m     ]\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     62\u001b[0m hist_mean_returns \u001b[38;5;241m=\u001b[39m ewma\u001b[38;5;241m.\u001b[39mget_returns()\n",
                        "File \u001b[1;32mC:\\Projects\\portfolio-analyzer\\src\\portfolio_analyzer\\return_estimator\\black_litterman_return.py:49\u001b[0m, in \u001b[0;36mBlackLittermanReturn.__init__\u001b[1;34m(self, view_vector, assets_in_view, view_confidence, config, data_fetcher)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview_vector \u001b[38;5;241m=\u001b[39m view_vector\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massets_in_view \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     42\u001b[0m     assets_in_view\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assets_in_view \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_assets_in_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview_vector)\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview_confidence \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     47\u001b[0m     view_confidence\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m view_confidence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_view_confidence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massets_in_view\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_views()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexcess_returns_cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_excess_returns_covariance()\n",
                        "File \u001b[1;32mC:\\Projects\\portfolio-analyzer\\src\\portfolio_analyzer\\return_estimator\\black_litterman_return.py:100\u001b[0m, in \u001b[0;36mBlackLittermanReturn._generate_view_confidence\u001b[1;34m(self, assets_in_view)\u001b[0m\n\u001b[0;32m     98\u001b[0m tau \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau\n\u001b[0;32m     99\u001b[0m assets \u001b[38;5;241m=\u001b[39m assets_in_view\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m--> 100\u001b[0m view_variance \u001b[38;5;241m=\u001b[39m tau \u001b[38;5;241m*\u001b[39m \u001b[43mdaily_cov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43massets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massets\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdiagonal()\n\u001b[0;32m    101\u001b[0m Omega \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m    102\u001b[0m     np\u001b[38;5;241m.\u001b[39mdiag(view_variance),\n\u001b[0;32m    103\u001b[0m     index\u001b[38;5;241m=\u001b[39massets,\n\u001b[0;32m    104\u001b[0m     columns\u001b[38;5;241m=\u001b[39massets,\n\u001b[0;32m    105\u001b[0m )\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Omega\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1375\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;66;03m# ugly hack for GH #836\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._multi_take\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m d \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m-> 1327\u001b[0m     axis: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS)\n\u001b[0;32m   1329\u001b[0m }\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(d, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Projects\\portfolio-analyzer\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[1;31mKeyError\u001b[0m: \"['KOG.OL', 'SHB-A.ST', 'SWED-A.ST'] not in index\""
                    ]
                }
            ],
            "source": [
                "# try:\n",
                "# The prepare_model_inputs function now internally handles the creation\n",
                "# of DCF-based views if enabled in the config.\n",
                "data_fetcher_instance = data_fetcher.DataFetcher(yf)\n",
                "model_inputs = ip.prepare_model_inputs(config, data_fetcher_instance)\n",
                "mean_returns = model_inputs.mean_returns\n",
                "cov_matrix = model_inputs.cov_matrix\n",
                "log_returns = model_inputs.log_returns\n",
                "close_df = model_inputs.close_df\n",
                "final_tickers = model_inputs.final_tickers\n",
                "# except Exception as e:\n",
                "#    print(f\"Data pipeline failed: {e}. Cannot proceed with analysis.\")\n",
                "#    mean_returns, cov_matrix, log_returns, close_df, final_tickers = (\n",
                "#        pd.Series(dtype=float),\n",
                "#        pd.DataFrame(),\n",
                "#        pd.DataFrame(),\n",
                "#        pd.DataFrame(),\n",
                "#        [],\n",
                "#    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the distribution of daily returns for the processed assets\n",
                "arithmetic_returns = log_returns.apply(lambda x: np.exp(x) - 1)\n",
                "plt.figure(figsize=(14, 7))\n",
                "sns.violinplot(data=arithmetic_returns, palette=\"Set2\", inner=\"quartile\", linewidth=1.5)\n",
                "plt.title(\"Distribution of Daily Arithmetic Returns by Asset\", fontsize=16, fontweight=\"bold\")\n",
                "plt.xlabel(\"Ticker\", fontsize=14)\n",
                "plt.ylabel(\"Daily Arithmetic Return\", fontsize=14)\n",
                "plt.xticks(rotation=45, ha=\"right\", fontsize=11)\n",
                "plt.yticks(fontsize=11)\n",
                "plt.grid(True, linestyle=\"--\", alpha=0.7, axis=\"y\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1. Review Model Return Estimates\n",
                "\n",
                "After running the pipeline, compare the following annualized return estimates for each asset:\n",
                "\n",
                "- **Historical (EWMA Shrunk):** Backward-looking returns based on historical prices.\n",
                "- **Implied Equilibrium:** Forward-looking returns implied by market capitalization weights.\n",
                "- **BL Posterior (Final):** The final blended return from the Black-Litterman model, combining equilibrium returns with DCF-based views. This vector is used for portfolio optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if \"model_inputs\" in locals() and model_inputs and not model_inputs.mean_returns.empty:\n",
                "    returns_df = pd.DataFrame(index=final_tickers)\n",
                "\n",
                "    # Convert annualized log returns to arithmetic\n",
                "    def log_to_arith(r):\n",
                "        return np.exp(r) - 1 if r is not None else None\n",
                "\n",
                "    returns_df[\"Historical\"] = model_inputs.hist_mean_returns.apply(log_to_arith)\n",
                "\n",
                "    if model_inputs.implied_equilibrium_returns is not None:\n",
                "        returns_df[\"Implied Equilibrium\"] = model_inputs.implied_equilibrium_returns.apply(\n",
                "            log_to_arith\n",
                "        )\n",
                "\n",
                "    returns_df[\"BL Posterior (Final)\"] = model_inputs.mean_returns.apply(log_to_arith)\n",
                "\n",
                "    # Display the DataFrame, formatted as percentages\n",
                "    display(\n",
                "        returns_df.style.format(\"{:.2%}\")\n",
                "        .background_gradient(cmap=\"viridis\", axis=0)\n",
                "        .set_caption(\"Comparison of Annualized Arithmetic Return Estimates\")\n",
                "        .set_properties(**{\"text-align\": \"right\"})\n",
                "        .highlight_max(axis=0, color=\"lightgreen\")\n",
                "        .highlight_min(axis=0, color=\"lightcoral\")\n",
                "    )\n",
                "else:\n",
                "    print(\"Model inputs not available. Cannot display return estimates.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing Asset Correlations\n",
                "\n",
                "Before optimization, it is essential to understand the relationships between selected assets. The correlation matrix and network graph below help assess diversification potential within the portfolio."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not cov_matrix.empty:\n",
                "    correlation_matrix_df = calculate_correlation_matrix(cov_matrix)\n",
                "\n",
                "    plot_correlation_heatmap(correlation_matrix_df)\n",
                "    plot_correlation_network(correlation_matrix_df, threshold=0.3)\n",
                "else:\n",
                "    print(\"Covariance matrix is empty. Skipping correlation plots.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Interactive Portfolio Optimization\n",
                "\n",
                "The next step is to determine the optimal portfolio weights by maximizing the Sharpe Ratio, subject to constraints such as maximum allocation per asset. The L2 regularization parameter (`lambda_reg`) can be adjusted interactively to control overfitting and promote diversification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = PortfolioOptimizer(\n",
                "    mean_returns=model_inputs.mean_returns,\n",
                "    cov_matrix=model_inputs.cov_matrix,\n",
                "    config=config,\n",
                ")\n",
                "\n",
                "stats_calculator = SimulationStatisticsCalculator(initial_value=config.monte_carlo.initial_value)\n",
                "\n",
                "mc_simulator = MonteCarloSimulator(config=config, stats_calculator=stats_calculator)\n",
                "\n",
                "session = PortfolioAnalysisSession(\n",
                "    config,\n",
                "    model_inputs,\n",
                "    optimizer=optimizer,\n",
                "    mc_simulator=mc_simulator,\n",
                ")\n",
                "\n",
                "print(\"--- Interactive Portfolio Optimization ---\")\n",
                "interact(\n",
                "    session.run_interactive_optimization,\n",
                "    lambda_reg=FloatSlider(\n",
                "        min=0.0,\n",
                "        max=2.0,\n",
                "        step=0.05,\n",
                "        value=config.optimization.lambda_reg,\n",
                "        description=\"L2 Lambda:\",\n",
                "        continuous_update=False,\n",
                "        layout={\"width\": \"500px\"},\n",
                "    ),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Monte Carlo Simulation\n",
                "\n",
                "To assess the potential future performance of the optimized portfolio, we run a Monte Carlo simulation. This projects thousands of possible future portfolio paths, quantifying the range of outcomes and associated risks. Simulation parameters, including the use of a Student’s t-distribution for fat tails, can be adjusted interactively."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n--- Monte Carlo Simulation ---\")\n",
                "interact(\n",
                "    session.run_interactive_monte_carlo,\n",
                "    num_sim_interactive=IntSlider(\n",
                "        min=1000,\n",
                "        max=100000,\n",
                "        step=1000,\n",
                "        value=config.monte_carlo.num_simulations,\n",
                "        description=\"Num Simulations:\",\n",
                "        continuous_update=False,\n",
                "        layout={\"width\": \"500px\"},\n",
                "    ),\n",
                "    time_horizon_interactive=FloatSlider(\n",
                "        min=0.5,\n",
                "        max=10.0,\n",
                "        step=0.5,\n",
                "        value=config.monte_carlo.time_horizon_years,\n",
                "        description=\"Time Horizon (Yrs):\",\n",
                "        continuous_update=False,\n",
                "        layout={\"width\": \"500px\"},\n",
                "    ),\n",
                "    df_t_interactive=IntSlider(\n",
                "        min=0,\n",
                "        max=30,\n",
                "        step=1,\n",
                "        value=config.monte_carlo.df_t_distribution,\n",
                "        description=\"Student-t df (0-2=Normal):\",\n",
                "        continuous_update=False,\n",
                "        layout={\"width\": \"500px\"},\n",
                "    ),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Efficient Frontier Analysis\n",
                "\n",
                "The efficient frontier illustrates the set of optimal portfolios offering the highest expected return for a given level of risk. This visualization highlights:\n",
                "\n",
                "- **Maximum Sharpe Ratio Portfolio:** The tangency portfolio with the best risk-adjusted return.\n",
                "- **Minimum Volatility Portfolio:** The portfolio with the lowest achievable risk.\n",
                "\n",
                "Both are key reference points for portfolio construction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Calculate and Plot the Efficient Frontier ---\n",
                "\n",
                "print(\"\\n--- Efficient Frontier Analysis ---\")\n",
                "\n",
                "if \"session\" in locals() and session.optimizer:\n",
                "    try:\n",
                "        frontier_df, max_sharpe_res, min_vol_res = session.optimizer.calculate_efficient_frontier()\n",
                "\n",
                "        print(\"\\nMaximum Sharpe Ratio Portfolio:\")\n",
                "        display(display_optimization_summary_html(max_sharpe_res))\n",
                "\n",
                "        print(\"\\nMinimum Volatility Portfolio:\")\n",
                "        display(display_optimization_summary_html(min_vol_res))\n",
                "\n",
                "        # Plot the efficient frontier, highlighting the interactively found portfolio\n",
                "        plot_efficient_frontier(\n",
                "            frontier_df,\n",
                "            max_sharpe_res,\n",
                "            min_vol_res,\n",
                "            current_opt_result=session.latest_result,\n",
                "        )\n",
                "    except Exception as e:\n",
                "        print(f\"Could not generate efficient frontier: {e}\")\n",
                "else:\n",
                "    print(\"Analysis session not initialized. Please run the interactive optimization cell first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Strategy Backtesting\n",
                "\n",
                "Finally, we conduct a historical backtest to evaluate the strategy’s real-world performance. The backtester rebalances the portfolio at a fixed frequency (e.g., quarterly), using a rolling lookback window to update optimization inputs at each step. Results are benchmarked against a relevant market index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a benchmark index to compare against\n",
                "# ^OSEBX is the Oslo Børs Benchmark Index\n",
                "\n",
                "\n",
                "benchmark_ticker = \"OSEBX.OL\"\n",
                "\n",
                "# Initialize and run the backtester\n",
                "backtester = Backtester(\n",
                "    config, optimizer_cls=PortfolioOptimizer, data_fetcher=data_fetcher_instance\n",
                ")\n",
                "backtest_results, performance_metrics = backtester.run(benchmark_ticker=benchmark_ticker)\n",
                "\n",
                "clear_output(wait=True)\n",
                "\n",
                "if not backtest_results.empty:\n",
                "    # Display performance metrics using the new reporting function\n",
                "    display(display_backtest_summary_html(performance_metrics))\n",
                "\n",
                "    # Plot the results using the new dedicated function\n",
                "    plot_backtest_results(backtest_results, benchmark_ticker)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Backtest did not produce any results.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
